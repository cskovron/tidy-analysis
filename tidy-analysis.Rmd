---
title:  |
        | Tools for tidy analysis 
author: |
        | Christopher Skovron
        | Northwestern University 
        | `R` User Group
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  revealjs::revealjs_presentation: 
    theme: simple
    highlight: haddock
    center: false
    transition: none
---



## Tidying up the analysis stage

See these slides and the Rmd on github:
http://github.com/cskovron/tidy-analysis


![](./figures/data-science-model.png)

## Check for some installations

```{r, eval=FALSE}
install.packages(c("tidyverse", "corrr","infer","dotwhisker"))
```

## Load packages we will need 

```{r, message=FALSE}
library(tidyverse)
library(corrr)
library(infer)
library(dotwhisker)
```


## The problem: a lack of convention in analysis and modeling packages 

- Lack of conventions for how models are specified in calls to modeling functions
- Lack of conventions 


## Fortunately, an emerging set of conventions on tidy principles

- e.g., [`parsnip`](https://topepo.github.io/parsnip/), a tool to unify model specification across packages
- [A draft set of tidy conventions for modeling packages](https://tidymodels.github.io/model-implementation-principles/index.html)
- But this is still largely under development


## Tools 

- `broom` - models
- `infer` - hypothesis testing
- `corrr` - tidy analysis of correlations 

## Additional modeling packages emerging 

- `recipes` simplifies getting design matrices
- `tidybayes` and `tidyposterior` 


## Tidy correlations with `corrr`

```{r}
#install.package('corrr')
library(corrr)
d <- correlate(mtcars)
d
```




## Using `infer` for tidy hypothesis testing

[`infer`](https://infer.netlify.com/reference/index.html) provides tidy tools for common hypothesis testing tasks including t-tests, chi-squared tests







Set up mtcars for the example analysis - mutate vars to factors

```{r}
mtcars <- as.data.frame(mtcars) %>%
  mutate(cyl = factor(cyl),
          vs = factor(vs),
          am = factor(am),
          gear = factor(gear),
          carb = factor(carb))
```

## Difference in proportions: the old way




## Difference in proportions with `infer`

```{r}
mtcars %>%
  specify(am ~ vs, success = "1") %>%
  hypothesize(null = "independence") %>%
  generate(reps = 100, type = "permute") %>%
  calculate(stat = "diff in props", order = c("1", "0"))
```


## `infer` functions

`specify()` - 
`hypothesize()` - 
`generate()` - 
`calculate()` - 


## Difference in means: the old way



## Difference in means with `infer`

```{r}
mtcars %>%
  specify(response = mpg, explanatory = am) %>%
  generate(reps = 100, type = "bootstrap") %>%
  calculate(stat = "diff in means", order = c("1", "0"))
```






## `broom` - tidy up modeling output 





## Tidy bootstrapping with `broom`



## Bootstrapping the old way


## Bootstrapping with `broom`


## `broom` tidies up regression output 

- output from `lm`, `glm`, `t.test` is ugly and not standardized
- `broom` transforms into easy-to-use matrices
- makes manipulating model output much easier
- especially useful if you're simulating a lot of models 


## Example: weight and mileage in `mtcars`

```{r, echo=TRUE}
library(ggplot2)
data(mtcars)
ggplot(mtcars, aes(mpg, wt)) + geom_point()
```


## Fit an nls model

```{r, echo=TRUE}
nlsfit <- nls(mpg ~ k / wt + b, mtcars, start=list(k=1, b=0))
summary(nlsfit)
```

## model 
```{r}
ggplot(mtcars, aes(wt, mpg)) + geom_point() + geom_line(aes(y=predict(nlsfit)))
```


## We want to bootstrap the confidence intervals


```{r, echo=TRUE, message = FALSE}
library(dplyr)
library(broom)
set.seed(2014)
bootnls <- mtcars %>% bootstrap(100) %>%
    do(tidy(nls(mpg ~ k / wt + b, ., start=list(k=1, b=0))))
```

## We get a clean `data.frame` that summarizes each replication 

```{r, echo=TRUE}
bootnls
```

## use the percentile method to calculate uncertainty 

```{r, echo=TRUE}
alpha = .05
bootnls %>% group_by(term) %>% 
  summarize(low=quantile(estimate, alpha / 2),
  high=quantile(estimate, 1 - alpha / 2))
```

## Or you can use `augment` to visualize the uncertainty in the curve:

```{r, echo=TRUE}
bootnls_aug <- mtcars %>% bootstrap(100) %>%
    do(augment(nls(mpg ~ k / wt + b, ., start=list(k=1, b=0)), .))

ggplot(bootnls_aug, aes(wt, mpg)) + geom_point() +
    geom_line(aes(y=.fitted, group=replicate), alpha=.2)
```


## `broom` and "the secret weapon"

- Gelman's "secret weapon" 
- Fit the same model repeatedly to different datasets 

## Use `dotwhisker` and `broom` to use the secret weapon in a tidy way 

```{r, tidy = TRUE}
#library(broom)
#library(dplyr)

# Estimate models across many samples, put results in a tidy data frame
by_clarity <- diamonds %>% 
  group_by(clarity) %>%
 do(broom::tidy(lm(price ~ carat + cut + color, data = .))) %>%
 ungroup %>% 
  rename(model = clarity)

# Generate a 'secret weapon' plot of the results of diamond size
secret_weapon(by_clarity, "carat")
```



